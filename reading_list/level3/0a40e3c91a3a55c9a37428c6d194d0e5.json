[{"name":"Human-AI-Interaction, Human-Machine-Interaction","num":{"":4,"Human-AI Symbiosis":2,"Bargaining With AI Systems":1,"Machine Advisors":1,"Human-AI Co-Creation":1,"Human-Robot Interaction, HRI":2,"Applications":1,"Guidelines":2,"Human-Agent Interaction":2,"Algorithmic Experience, AX":1,"Metaphors, Meaning":2,"Theory of Mind":1,"Replicant Effect":1,"Incidental Learning":1,"Human-AI Partnerships":2,"Algorithmic Resistance":1,"Socially Situated Artificial Intelligence":1,"Co-Creation":5,"Imperfect Users":1,"Intelligible AI":2,"Human-Machine Era":1,"Co-Creativity":1,"Collaboration":2,"Coactive Design":1,"Synergy":1,"Design for Autonomy":2,"Levels of Autonomy (LoA)":5,"Research Questions":1,"Society of Mind":1,"Embodied Agents":2,"Public Displays":1,"LLM Objects":1,"Issues":1}},{"name":"Issues","num":{"Exploitation":1,"Human-AI Alignment":13,"Ideology":1,"Auditing":3,"Dilemmas":2,"Hype":1,"Ethics":12,"Autonomous Weapons":6,"Technological Determinism":1,"Predictability and Surprise":1,"Future Shock":1,"The Most Important Century":1,"Transparency":1,"AI Companions":1,"False Empathy":1,"AI Effect":1,"Lobbying":1,"Fairness":2,"AI Safety":1,"Awful AI":2,"Governance, Regulation, Legislation":10,"Future Society":1,"Public Discourse, Public Debate":1,"AI Literacy":1,"Trust":3,"Capability Overhang":1,"Malicious Use":1,"Existential Risk":2,"Harm":1,"Sustainability":1,"AI Winter":1}},{"name":"Explainable AI, XAI","num":{"":6,"Interpretability":10,"General":6,"Measures for Explainability":1,"User Algorithm Assumptions":1,"Human-centered Explainable AI":1,"Nutrition Label":1,"Systems, Tools":1,"Right to an Explanation":1,"Analogies":1,"Example-based Explanation":1,"Folk Theories":18,"Trust and Model Accuracy":1,"Model Cards, Fact Sheets":2,"Progressive Disclosure":1,"Evaluative AI":1,"Issues":2,"Language Models for Explainable AI":1,"System Model, User Model":1,"Rashomon Effect":1,"Activation Atlases":1}},{"name":"General, Theory","num":{"":3,"Cognitive Computing":1,"Superintelligence":1,"Definition of AI":1,"AI Winter, AI Summer":1,"Socratic Wisdom, Socratic Ignorance":1,"Nordic Countries":1,"The New Electricity":1}},{"name":"General Intelligence, AGI","num":{"":2,"Common Sense":1,"Human Mind":1,"Evaluating AGI":2,"General Agent":1,"Consciousness":2}},{"name":"Guidelines, Policies","num":{"":2,"AI Bill of Rights":2,"Ethics Guidelines for Trustworthy AI":1,"AI Risk Management Framework (AI RMF)":1,"FIRE Principles":1,"AI Principles":3}},{"name":"Collaboration, Cooperation","num":{"":2,"CASA, Computers are Social Actors (Nass)":1,"Applications":1,"Github Copilot":1,"Man-Computer Symbiosis (Licklider)":1}},{"name":"Human-Centered AI, HCAI","num":{"":4,"Issues":2,"Human-centered AI Canvas":2,"Contextual Morality Framework":1}},{"name":"Impact, Future","num":{"AI100":3,"Impact Statements":1,"Productivity Paradox":1}},{"name":"Foundation Models","num":{"":3,"Visual ChatGPT":1}},{"name":"Human-Computer Integration","num":{"":2,"Challenges":1}},{"name":"Responsible AI","num":{"Responsible AI Art":1,"":1}},{"name":"Turing Test","num":{"":1,"Minimal Turing Test":1}},{"name":"State of AI","num":{"AI index":3,"MMC Ventures":1}},{"name":"GenZ","num":{"":1}},{"name":"Machine Behaviour","num":{"":1}},{"name":"Humanics","num":{"":1}},{"name":"Mundane AI Future","num":{"Experiential Design Fiction":1}},{"name":"Designing AI Systems","num":{"":1}},{"name":"Slow AI","num":{"":1}},{"name":"Applications","num":{"Social Mechanisms":1}},{"name":"Affective AI","num":{"Sociopath AI":1}},{"name":"Action Selection","num":{"":1}},{"name":"Intelligent Personal Assistants, IPA","num":{"Roles":1}},{"name":"Synthetic Data","num":{"":2}},{"name":"Military","num":{"Ethical Principles":1}},{"name":"Singularity","num":{"Natural Selection, Darwinian Forces":1}},{"name":"History","num":{"Dartmouth Workshop":1}}]