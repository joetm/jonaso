[{"name":"Training Data","num":4},{"name":"Unified Language Learning","num":2},{"name":"Scaling","num":2},{"name":"ALiBi","num":2},{"name":"General, Theory","num":2},{"name":"Continual Pre-Training","num":2},{"name":"Ulysses (DeepSpeed)","num":1},{"name":"LUMI Scaling","num":1},{"name":"Gap Between LLMs and Children","num":1},{"name":"Finetuning vs Pretraining","num":1},{"name":"LLMs as Training Data Generator","num":1},{"name":"Training with Organic Interactions","num":1},{"name":"Gap Between LLMs and Humans","num":1},{"name":"Megatron-DeepSpeed","num":1},{"name":"ParlAI","num":1},{"name":"Data Augmentation","num":1},{"name":"Data Management","num":1},{"name":"Data Preparation","num":1},{"name":"Data Selection","num":1}]