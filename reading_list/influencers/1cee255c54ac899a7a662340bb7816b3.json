{"docs":[{"title":"Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks","priority":1},{"title":"Longformer: The Long-Document Transformer","priority":1},{"title":"SPECTER: Document-level Representation Learning using Citation-informed Transformers","priority":1}],"keywords":["Machine Learning","General, Theory","Training","NLP","Language Models","Longformer","Specter"]}