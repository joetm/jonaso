{"docs":[{"title":"Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models","priority":3},{"title":"AI poisoning tool Nightshade received 250,000 downloads in 5 days: \u2018beyond anything we imagined\u2019","priority":1},{"title":"Nightshade: Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models","priority":2}],"keywords":["Machine Learning","Generative Deep Learning","Issues","Data Poisoning","Prompt-specific Poisoning Attacks","Nightshade","Copyright, Intellectual Property","Protecting Images"]}