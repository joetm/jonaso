{"docs":[{"title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model","priority":1},{"title":"Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text","priority":0},{"title":"Closed AI Models Make Bad Baselines","priority":1},{"title":"Green AI","priority":1},{"title":"Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping","priority":3},{"title":"WHAT\u2019S IN MY BIG DATA?","priority":3}],"keywords":["NLP","Language Models","BLOOM","Benchmarks, gold standards, datasets","Images","Multimodal C4 (MMC4)","Machine Learning","Evaluation","Issues","Closed Models Baselines","AI","Sustainability","Red AI, Green AI","Fine-Tuning","Random Seeds, Brittleness","Early Stopping","Training","Training Data","What's in My Big Data (WIMBD)"]}