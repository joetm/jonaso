{"docs":[{"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models","priority":3},{"title":"SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS","priority":2},{"title":"Crowdsourcing User Studies With Mechanical Turk","priority":3},{"title":"And Now for Something Completely Different: Improving Crowdsourcing Workflows with Micro-Diversions","priority":2},{"title":"Emergent Abilities of Large Language Models","priority":3},{"title":"Scaling Instruction-Finetuned Language Models","priority":1},{"title":"He Says, She Says: Conflict and Coordination in Wikipedia","priority":1},{"title":"Putting Fairness Principles into Practice: Challenges, Metrics, and Improvements","priority":0},{"title":"Social Information Foraging and Collaborative Search","priority":0},{"title":"TAKE A STEP BACK: EVOKING REASONING VIA AB- STRACTION IN LARGE LANGUAGE MODELS","priority":3}],"keywords":["Prompt Engineering","Prompt Techniques","Chain of Thought, CoT","Self-Consistency, CoT-SC","Crowdsourcing, Human Computation","Applications","User Studies","Process, Workflow, Worker Selection","Diversions","NLP","General, Theory","Emergent Abilities","Language Models","Flan-T5","Instruction Finetuning","Collective Intelligence","Machine Learning","Issues","Fairness","Fairness Metrics","Conditional Equality","Information Retrieval","Information Foraging","Social Information Foraging, Collaborative Search","Step-Back Prompting"]}