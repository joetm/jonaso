{"docs":[{"title":"LARGE LANGUAGE MODELS","priority":3},{"title":"LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE MODELS","priority":1},{"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models","priority":3},{"title":"SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS","priority":2},{"title":"Natural Questions: A Benchmark for Question Answering Research","priority":1},{"title":"FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS","priority":1},{"title":"Scaling Instruction-Finetuned Language Models","priority":1},{"title":"Towards a Human-like Open-Domain Chatbot","priority":1},{"title":"AutoAugment: Learning Augmentation Strategies from Data","priority":1},{"title":"EfficientDet: Scalable and Efficient Object Detection","priority":0},{"title":"HYPERNETWORKS","priority":2},{"title":"TAKE A STEP BACK: EVOKING REASONING VIA AB- STRACTION IN LARGE LANGUAGE MODELS","priority":3},{"title":"SELF-DISCOVER: Large Language Models Self-Compose Reasoning Structures","priority":1},{"title":"LONG-FORM FACTUALITY IN LARGE LANGUAGE MODELS","priority":2}],"keywords":["Prompt Engineering","Applications","Optimization","Optimization by Prompting (OPRO)","Prompt Techniques","Least-to-most Prompting","Chain of Thought, CoT","Self-Consistency, CoT-SC","Benchmarks, gold standards, datasets","Question Answering","Natural Questions","NLP","Fine-Tuning","Instruction Tuning","Language Models","Flan-T5","Instruction Finetuning","Meena (Google)","Measuring Human Likeness","Sensibleness and Speci\ufb01city Average (SSA)","Machine Learning","Computer Vision","Data Augmentation","AutoAugment","Object Detection","EfficientDet","Generative Deep Learning","Text-to-Image","Stable Diffusion","Fine-tuning Stable Diffusion","Hypernetworks","Step-Back Prompting","Reasoning","Self-Discover","Issues","Hallucination, Factual Information","Search-Augmented Factuality Evaluator (SAFE)"]}