{"docs":[{"title":"LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE MODELS","priority":1},{"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models","priority":2},{"title":"SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS","priority":1},{"title":"Natural Questions: A Benchmark for Question Answering Research","priority":1},{"title":"FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS","priority":1},{"title":"Scaling Instruction-Finetuned Language Models","priority":1},{"title":"AutoAugment: Learning Augmentation Strategies from Data","priority":1},{"title":"EfficientDet: Scalable and Efficient Object Detection","priority":0},{"title":"HYPERNETWORKS","priority":2},{"title":"Towards a Human-like Open-Domain Chatbot","priority":1}],"keywords":["Prompt Engineering","Prompt Techniques","Least-to-most Prompting","Chain of Thought Prompting","Self-Consistency","Benchmarks, gold standards, datasets","Question Answering","NLP","Fine-Tuning","Instruction Tuning","Language Models","Flan-T5","Instruction Finetuning","Machine Learning","Computer Vision","Augmentation","AutoAugment","Applications","Object Detection","EfficientDet","Training","Hypernetworks","Meena (Google)","Measuring Human Likeness","Sensibleness and Speci\ufb01city Average (SSA)"]}