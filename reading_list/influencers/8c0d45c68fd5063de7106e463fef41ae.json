{"docs":[{"title":"The Capacity for Moral Self-Correction in Large Language Models","priority":3},{"title":"Discovering Language Model Behaviors with Model-Written Evaluations","priority":2},{"title":"Constitutional AI: Harmlessness from AI Feedback","priority":3},{"title":"Confidence-Building Measures for Artificial Intelligence: Workshop Proceedings","priority":1}],"keywords":["Prompt Engineering","Prompt Techniques","Moral Self-Correction","NLP","Issues","Scaling","Inverse Scaling","Model-Written Evaluations","Machine Learning","Reinforcement Learning","Reinforcement Learning with Human Feedback (RLHF)","Constitutional AI","AI","Confidence-Building Measures (CBMs)"]}