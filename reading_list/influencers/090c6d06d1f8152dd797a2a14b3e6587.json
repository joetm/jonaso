{"docs":[{"title":"Pretraining Language Models with Human Preferences","priority":2},{"title":"B E Y O N D T H E I M I TAT I O N G A M E : Q U A N T I F Y- I N G A N D E X T R A P O L AT I N G T H E C A PA B I L I T I E S O F L A N G U A G E M O D E L S","priority":1},{"title":"Delays, Detours, and Forks in the Road: Latent State Models of Training Dynamics","priority":1}],"keywords":["AI","Issues","Human-AI Alignment","Human Preferences","Benchmarks, gold standards, datasets","NLP","Beyond the Imitation Game (BIG-Bench)","Machine Learning","Generative Deep Learning","Text-to-Image","Seed","Hidden Markov Model","Detour"]}