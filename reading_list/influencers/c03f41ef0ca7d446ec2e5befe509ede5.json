{"docs":[{"title":"Training language models to follow instructions with human feedback","priority":3},{"title":"The Second Conversational Intelligence Challenge (ConvAI2)","priority":0},{"title":"Learning to summarize from human feedback","priority":2},{"title":"What are human values, and how do we align AI to them?","priority":3}],"keywords":["AI","Issues","Human-AI Alignment","InstructGPT","Benchmarks, gold standards, datasets","Chat, Conversations","ConvAI2","Machine Learning","Reinforcement Learning","Reinforcement Learning with Human Feedback (RLHF)","Alignment with Human Values","Human Values","Moral Graph Elicitation (MGE)"]}