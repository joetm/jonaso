{"docs":[{"title":"Data Poisoning Attacks and Defenses to Crowdsourcing Systems","priority":0},{"title":"SneakyPrompt: Jailbreaking Text-to-image Generative Models","priority":3},{"title":"A SURVEY ON POST-TRAINING OF LARGE LANGUAGE MODELS","priority":2}],"keywords":["Crowdsourcing, Human Computation","Issues","Malicious Use, Negative Side Effects","Data Poisoning Attacks","NLP","Adversarial Attacks","Jailbreaks","SneakyPrompt","Training","Post-Training"]}