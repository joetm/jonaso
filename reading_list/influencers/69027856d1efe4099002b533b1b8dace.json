{"docs":[{"title":"On the Opportunities and Risks of Foundation Models","priority":3},{"title":"Holistic Evaluation of Language Models","priority":2},{"title":"Unifying Human and Statistical Evaluation for Natural Language Generation","priority":1},{"title":"Emergent Abilities of Large Language Models","priority":3},{"title":"Condemning the deployment of GPT-4chan","priority":0},{"title":"The Disagreement Deconvolution: Bringing Machine Learning Performance Metrics In Line With Reality","priority":3},{"title":"A Survey on Data Selection for Language Models","priority":3},{"title":"Observational Scaling Laws and the Predictability of Language Model Performance","priority":3},{"title":"Can LLMs Generate Novel Research Ideas?","priority":3}],"keywords":["AI","Foundation Models","NLP","Evaluation","Holistic Evaluation of Language Models (HELM)","Human Uni\ufb01ed with Statistical Evaluation (HUSE)","General, Theory","Emergent Abilities","Language Models","GPT","GPT-4chan","Machine Learning","Issues","Disagreement Deconvolution","Training","Data Selection","Scaling","Scaling Laws","Observational Scaling Laws","Future Science","Research Ideas"]}