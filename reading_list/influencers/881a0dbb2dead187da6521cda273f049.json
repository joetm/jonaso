{"docs":[{"title":"LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models","priority":3},{"title":"A Survey on Large Language Model based Autonomous Agents","priority":3},{"title":"Profile Inference Revisited","priority":0},{"title":"Analysis_of_factors_associated_with_disease.99363","priority":0},{"title":"The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits","priority":2},{"title":"T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Mixed Large Language Model Signals for Science Question Answering","priority":2}],"keywords":["NLP","Fine-Tuning","Adapter","LLM-Adapters","Agents, Autonomous Task Management","Machine Learning","Applications","Profile Inference, Profile Rectification","Pandemics","Corona Virus Pandemic","Causes","Optimization","Quantization","1-bit LLMs","BitNet","BitNet b1.58","Question Answering","Visual Question Answering","T-SciQ"]}