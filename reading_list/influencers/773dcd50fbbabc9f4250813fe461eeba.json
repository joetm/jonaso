{"docs":[{"title":"Thinking Like Transformers","priority":1},{"title":"Some remarks on Large Language Models","priority":1},{"title":"Getting More Out Of Syntax with PROPS","priority":0},{"title":"DALLE-2 is Seeing Double: Flaws in Word-to-Concept Mapping in Text2Image Models","priority":2},{"title":"Reinforcement Learning for Language Models","priority":2}],"keywords":["NLP","Transformers","Restricted Access Sequence Processing (RASP)","Issues","Information Extraction","Open Information Extraction, OIE","Systems","PropS","Machine Learning","Generative Deep Learning","Semantic Leakage","Reinforcement Learning","Reinforcement Learning with Human Feedback (RLHF)","Reinforcement Learning versus Instruction Tuning"]}