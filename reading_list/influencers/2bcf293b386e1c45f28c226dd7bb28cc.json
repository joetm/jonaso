{"docs":[{"title":"LIMA: Less Is More for Alignment","priority":2},{"title":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing","priority":3},{"title":"Generative AI Research Benchmarking Benchmark Leakage in Large Language Models","priority":3},{"title":"AlphaGo Moment for Model Architecture Discovery","priority":0},{"title":"ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientifi c Inquiry","priority":3}],"keywords":["AI","Issues","Human-AI Alignment","LIMA","Prompt Engineering","General, Theory","NLP","Evaluation Data Contamination","Benchmark Leakage","Benchmark Transparency Card","Future Science","Applications","Model Architecture Discovery","ASI-ARCH","Benchmarks, gold standards, datasets","Science","ResearcherBench"]}