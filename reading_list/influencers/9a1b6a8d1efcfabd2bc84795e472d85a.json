{"docs":[{"title":"GPT Understands, Too","priority":1},{"title":"AgentBench: Evaluating LLMs as Agents","priority":2},{"title":"GPT Can Solve Mathematical Problems Without a Calculator","priority":0},{"title":"Evaluating Large Language Models Trained on Code","priority":3},{"title":"CogView: Mastering Text-to-Image Generation via Transformers","priority":0},{"title":"CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers","priority":3},{"title":"CogAgent: A Visual Language Model for GUI Agents","priority":3},{"title":"CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers","priority":1},{"title":"COGVLM: VISUAL EXPERT FOR LARGE LANGUAGE MODELS","priority":3},{"title":"Attention: to Better Stand on the Shoulders of Giants","priority":2},{"title":"International Scientific Collaboration in Artificial Intelligence An Analysis based on Web Data","priority":1}],"keywords":["Prompt Engineering","Prompt Learning","Soft Prompts","P-tuning","Benchmarks, gold standards, datasets","NLP","Agents","AgentBench","Issues","Math","MathGLM","Language Models","Codex (OpenAI)","Machine Learning","Generative Deep Learning","Text-to-Image","CogView","CogView2","Multimodal LLMs","Cogagent","Text-To-Video","CogVideo","CogVLM","Citations","Cumulative Advantage","Attention","Collaboration","International Collaboration"]}