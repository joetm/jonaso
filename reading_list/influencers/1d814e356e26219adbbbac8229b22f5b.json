{"docs":[{"title":"A Cookbook of Self-Supervised Learning","priority":2},{"title":"GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection","priority":2},{"title":"H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models","priority":2},{"title":"META-REWARDING LANGUAGE MODELS: Self-Improving Alignment with LLM-as-a-Meta-Judge","priority":3},{"title":"Training Large LanguageModels to Reason in a Continuous Latent Space","priority":3},{"title":"Agent-as-a-Judge: Evaluate Agents with Agents","priority":3}],"keywords":["Machine Learning","Deep Learning","Self Supervised Learning","NLP","Fine-Tuning","Low-Rank Adaptation (LoRA)","GaLore","Inference","Heavy-Hitter Oracle (H2O)","Aligning Language Models","Self-Rewarding Language Models","Self-Improving Alignment","LLM-as-a-Meta-Judge","Reasoning","Reasoning in Latent Space","Coconut (Chain of Continuous Thought)","Prompt Engineering","Agents, Autonomous Task Management","Evaluation","Agent-as-a-Judge"]}