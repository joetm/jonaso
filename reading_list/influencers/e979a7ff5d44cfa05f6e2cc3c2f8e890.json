{"docs":[{"title":"Everyday Algorithm Auditing: Understanding the Power of Everyday Users in Surfacing Harmful Algorithmic Behaviors","priority":3},{"title":"User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms","priority":2},{"title":"Exposure to the Invisible: Algorithm Awareness from the Individual to the Collective","priority":0},{"title":"\u201cI always assumed that I wasn\u2019t really that close to [her]\u201d: Reasoning about Invisible Algorithms in News Feeds","priority":1},{"title":"First I \u201clike\u201d it, then I hide it: Folk Theories of Social Feeds","priority":3},{"title":"MIRAGE: Multi-model Interface for Reviewing and Auditing Generative Text-to-Image AI","priority":1}],"keywords":["AI","Issues","Auditing","Explainable AI, XAI","Algorithm Awareness","Folk Theories","Social Media News Feeds","Facebook","Machine Learning","Generative Deep Learning","Text-to-Image","Text-to-Image Models","Stable Diffusion","User Interfaces (UIs)","Mirage"]}