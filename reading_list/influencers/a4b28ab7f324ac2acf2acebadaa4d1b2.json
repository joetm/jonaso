{"docs":[{"title":"A Theory on Adam Instability in Large-Scale Machine Learning","priority":0},{"title":"OPT: Open Pre-trained Transformer Language Models","priority":3},{"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models","priority":3}],"keywords":["NLP","Issues","Training Instability","Adam Instability","Language Models","OPT (Meta)","LLaMA (Meta)","Llama 2"]}