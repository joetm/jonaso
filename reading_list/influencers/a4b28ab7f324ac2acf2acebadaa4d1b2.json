{"docs":[{"title":"OPT: Open Pre-trained Transformer Language Models","priority":3},{"title":"A Theory on Adam Instability in Large-Scale Machine Learning","priority":0},{"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models","priority":3}],"keywords":["NLP","Language Models","OPT (Meta)","Issues","Training Instability","Adam Instability","LLaMA (Meta)","Llama 2"]}