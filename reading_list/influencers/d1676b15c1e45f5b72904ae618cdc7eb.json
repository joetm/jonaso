{"docs":[{"title":"A Watermark for Large Language Models","priority":1},{"title":"Universal Guidance for Diffusion Models","priority":1},{"title":"Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise","priority":2},{"title":"A Cookbook of Self-Supervised Learning","priority":2},{"title":"Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models","priority":2},{"title":"Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text","priority":1},{"title":"Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery","priority":2},{"title":"Understanding and Mitigating Copying in Diffusion Models","priority":2},{"title":"Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models","priority":2}],"keywords":["NLP","Issues","Detection","Watermarks","Machine Learning","Generative Deep Learning","Guidance","Universal Guidance","Diffusion","Deep Learning","Self Supervised Learning","Security Vulnerabilities","Training Data Poisoning","Privacy Backdoors","Natural Language Generation, NLG","Detecting AI-Generated Text","Binoculars","Prompt Engineering","Prompt Learning","Discrete Prompt Optimization","PEZ","Data Replication, Memorization of Training Data"]}