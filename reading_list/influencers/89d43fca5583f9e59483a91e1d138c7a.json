{"docs":[{"title":"Replacing softmax with ReLU in Vision Transformers","priority":0},{"title":"Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models","priority":1}],"keywords":["Machine Learning","Computer Vision","Vision Transformers, ViT","ReLU Attention","NLP","Fine-Tuning","Self-Training","ReSTEM"]}