{"docs":[{"title":"Meet Nightshade, the new tool allowing artists to \u2018poison\u2019 AI models with corrupted training data","priority":0},{"title":"Meta publicly launches AI image generator trained on your Facebook, Instagram photos","priority":0},{"title":"Mistral CEO confirms \u2018leak\u2019 of new open source AI model nearing GPT-4 performance","priority":0},{"title":"AI poisoning tool Nightshade received 250,000 downloads in 5 days: \u2018beyond anything we imagined\u2019","priority":1}],"keywords":["Machine Learning","Generative Deep Learning","Issues","Data Poisoning","Prompt-specific Poisoning Attacks","Nightshade","Text-to-Image","Copyright","NLP","Language Models","miqu-1-70b"]}