{"docs":[{"title":"Replacing softmax with ReLU in Vision Transformers","priority":0},{"title":"Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)","priority":0}],"keywords":["Machine Learning","Computer Vision","Vision Transformers, ViT","ReLU Attention","Issues","Interpretability"]}