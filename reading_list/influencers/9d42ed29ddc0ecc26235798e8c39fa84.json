{"docs":[{"title":"Crowdsourcing for Search and Data Mining","priority":0},{"title":"Crowdsourcing Information Extraction for Biomedical Systematic Reviews","priority":0},{"title":"Design Activism for Minimum Wage Crowd Work","priority":2},{"title":"Beyond Mechanical Turk: An Analysis of Paid Crowd Work Platforms","priority":1},{"title":"The Future of Crowd Work","priority":3},{"title":"Beyond Mechanical Turk: An Analysis of Paid Crowd Work Platforms","priority":1},{"title":"Your Behavior Signals Your Reliability: Modeling Crowd Behavioral Traces to Ensure Quality Relevance Annotations","priority":0},{"title":"Why Is That Relevant? Collecting Annotator Rationales for Relevance Judgments","priority":2},{"title":"Probabilistic Modeling for Crowdsourcing Partially-Subjective Ratings","priority":0}],"keywords":["Crowdsourcing, Human Computation","Applications","Search, Querying, Human Flesh Engine, Search Support","Information Extraction","Pricing","Comparisons","Future of Work","Crowdsourcing, Microtasks","Process, Workflow, Worker Selection, Task Design","Worker Selection","Task Design","Rationales","Issues","Subjectivity, Subjective Tasks"]}