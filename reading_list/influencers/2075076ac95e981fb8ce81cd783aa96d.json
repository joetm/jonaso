{"docs":[{"title":"On the state of reporting in crowdsourcing experiments and a checklist to aid current practices","priority":0},{"title":"Quality Control in Crowdsourcing: A Survey of Quality Attributes, Assessment Techniques, and Assurance Actions","priority":3},{"title":"Issues and Directions","priority":1},{"title":"Quality Control in Crowdsourcing: A Survey of Quality Attributes, Assessment Techniques and Assurance Actions","priority":2},{"title":"Crowdsourcing Syntactically Diverse Paraphrases with Diversity-Aware Prompts and Workflows","priority":1},{"title":"Crowdsourcing Paper Screening in Systematic Literature Reviews","priority":0},{"title":"Crowd-based Multi-Predicate Screening of Papers in Literature Reviews","priority":1}],"keywords":["Crowdsourcing, Human Computation","Best Practices","Reporting Crowdsourcing Experiments","Checklist for Reporting Crowdsourcing Experiments","Issues","Quality, Accuracy","Applications","Paraphrases","Research","Literature review, paper screening","CrowdRev"]}