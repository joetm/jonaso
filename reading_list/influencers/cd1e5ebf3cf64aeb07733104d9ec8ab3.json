{"docs":[{"title":"Measuring Faithfulness in Chain-of-Thought Reasoning","priority":2},{"title":"SLEEPER AGENTS: TRAINING DECEPTIVE LLMS","priority":1},{"title":"ALIGNMENT FAKING IN LARGE LANGUAGE MODELS","priority":2}],"keywords":["Prompt Engineering","Prompt Techniques","Chain of Thought, CoT","NLP","Agents, Autonomous Task Management","Issues","Sleeper Agents","AI","Human-AI Alignment","Alignment Faking"]}