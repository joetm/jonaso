{"docs":[{"title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model","priority":1},{"title":"No \u201cZero-Shot\u201d Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance","priority":3}],"keywords":["NLP","Language Models","BLOOM","Machine Learning","Deep Learning","Issues","Generalization","Long-tail Data","Let It Wag"]}