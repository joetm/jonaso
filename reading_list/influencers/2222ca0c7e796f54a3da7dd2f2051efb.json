{"docs":[{"title":"Training language models to follow instructions with human feedback","priority":3},{"title":"Learning to summarize from human feedback","priority":2},{"title":"Deep Reinforcement Learning from Human Preferences","priority":2},{"title":"SLEEPER AGENTS: TRAINING DECEPTIVE LLMS","priority":1}],"keywords":["AI","Issues","Human-AI Alignment","InstructGPT","Machine Learning","Reinforcement Learning","Reinforcement Learning with Human Feedback (RLHF)","NLP","Agents, Autonomous Task Management","Sleeper Agents"]}