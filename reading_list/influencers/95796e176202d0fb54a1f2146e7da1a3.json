{"docs":[{"title":"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge","priority":1},{"title":"Bytes Are All You Need: Transformers Operating Directly On File Bytes","priority":1},{"title":"SAM-CLIP: MERGING VISION FOUNDATION MODELS TOWARDS SEMANTIC AND SPATIAL UNDERSTANDING","priority":1}],"keywords":["Benchmarks, gold standards, datasets","Search, Question-Answering","Visual Question-Answering","OK-VQA","NLP","Transformers","ByteFormer","Machine Learning","Contrastive Learning, Multimodal Models","CLIP","SAM-CLIP"]}