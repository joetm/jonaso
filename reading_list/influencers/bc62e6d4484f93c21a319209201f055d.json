{"docs":[{"title":"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?","priority":2},{"title":"Evaluating Machines by their Real-World Language Use","priority":0},{"title":"CLIPScore: A Reference-free Evaluation Metric for Image Captioning","priority":1},{"title":"QLORA: Efficient Finetuning of Quantized LLMs","priority":2},{"title":"Byte Latent Transformer: Patches Scale Better Than Tokens","priority":3}],"keywords":["NLP","In-Context Learning","Meaning","Evaluation","TuringAdvice","Machine Learning","Generative Deep Learning","Evaluating Generative Models","CLIP Score","Text-to-Image","Stable Diffusion","Fine-tuning Stable Diffusion","Low-Rank Adaptation, LoRA","qLoRA","Transformers","Byte Latent Transformer"]}