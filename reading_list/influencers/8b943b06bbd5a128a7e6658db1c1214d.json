{"docs":[{"title":"On the Opportunities and Risks of Foundation Models","priority":3},{"title":"You Only Live Once: Single-Life Reinforcement Learning","priority":0},{"title":"Robot Parkour Learning","priority":0},{"title":"Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation","priority":0},{"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model","priority":2}],"keywords":["AI","Foundation Models","Machine Learning","Reinforcement Learning","Single-Life Reinforcement Learning","Q-weighted adversarial learning, QWALE","Robots, Bots","Parkour","Models","Mobile ALOHA","Reinforcement Learning with Human Feedback (RLHF)","Direct Preference Optimization (DPO)"]}