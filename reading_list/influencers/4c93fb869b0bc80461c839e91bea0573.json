{"docs":[{"title":"Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V","priority":3},{"title":"Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing","priority":2},{"title":"Evaluation of Text Generation: A Survey","priority":3},{"title":"K-LITE: Learning Transferable Visual Models with External Knowledge","priority":1},{"title":"GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation","priority":1},{"title":"Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models","priority":3},{"title":"A SURVEY ON POST-TRAINING OF LARGE LANGUAGE MODELS","priority":2}],"keywords":["Prompt Engineering","Prompt Techniques","Set-of-Mark Prompting","NLP","Training","Finetuning vs Pretraining","Domain-Specific Language Models","Biomedical NLP","Evaluation","Machine Learning","Applications","Computer Vision","Image Classification","External Knowledge","K-LITE","Multimodal LLMs","GPT-4V(ision)","GUI Navigation","Generative Deep Learning","Text-To-Video","Sora","Post-Training"]}