{"docs":[{"title":"DINOv2: Learning Robust Visual Features without Supervision","priority":2},{"title":"Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning","priority":1},{"title":"DEMYSTIFYING CLIP DATA","priority":3},{"title":"APicture isWorthMore Than 77 Text Tokens: Evaluating CLIP-StyleModels on Dense Captions","priority":1}],"keywords":["Machine Learning","Computer Vision","DINOv2","Generative Deep Learning","Multimodal Generation","CM3Leon","Contrastive Learning, Multimodal Models","CLIP","MetaCLIP,  Metadata-Curated Language-Image Pre-training","Densely Captioned Image Dataset"]}