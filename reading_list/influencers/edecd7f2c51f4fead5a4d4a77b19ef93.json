{"docs":[{"title":"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?","priority":2},{"title":"MEASURING AND NARROWING THE COMPOSITIONALITY GAP IN LANGUAGE MODELS","priority":2},{"title":"OLMoE: Open Mixture-of-Experts Language Models","priority":1}],"keywords":["NLP","In-Context Learning","Meaning","Prompt Engineering","Prompt Techniques","Self-Ask Prompt","Compositionality Gap","Fine-Tuning","Merging, Blending","Mixture of Experts","Open Mixture-of-Experts (OlMoE)"]}