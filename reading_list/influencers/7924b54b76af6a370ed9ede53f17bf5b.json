{"titles":[{"title":"Empirical Methodology for Crowdsourcing Ground Truth","priority":1},{"title":"Identifying Research Talent Using Web-Centric Databases","priority":0},{"title":"Disagreement in Crowdsourcing and Active Learning for Better Distant Supervision Quality","priority":0},{"title":"Capturing Ambiguity in Crowdsourcing Frame Disambiguation","priority":0},{"title":"CrowdTruth 2.0: Quality Metrics for Crowdsourcing with Disagreement","priority":0},{"title":"CrowdTruth: Machine-Human Computation Framework for Harnessing Disagreement in Gathering Annotated Data","priority":0},{"title":"Truth in Disagreement Crowdsourcing Labeled Data for Natural Language Processing","priority":0},{"title":"Capturing Ambiguity in Crowdsourcing Frame Disambiguation","priority":0},{"title":"Capturing Ambiguity in Crowdsourcing Frame Disambiguation","priority":0}],"keywords":["Crowdsourcing, Human Computation","Process, Workflow, Worker Selection, Task Design","CrowdTruth","Knowledge","Ontology Engineering","Crowdsourcing"]}