{"docs":[{"title":"Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor","priority":1},{"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models","priority":3},{"title":"Toolformer: Language Models Can Teach Themselves to Use Tools","priority":3},{"title":"Galactica: A Large Language Model for Science","priority":3},{"title":"Nougat: Neural Optical Understanding for Academic Documents","priority":2}],"keywords":["Prompt Engineering","Prompt Learning","Soft Prompts","Instruction Tuning","Unnatural Instructions","NLP","Language Models","LLaMA (Meta)","Llama 2","External Knowledge Bases","Toolformer (Meta)","Future Science","Galactica (Meta)","Machine Learning","Applications","Science Parsers","Nougat"]}