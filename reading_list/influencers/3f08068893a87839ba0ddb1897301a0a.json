{"docs":[{"title":"Evaluating Large Language Models Trained on Code","priority":3},{"title":"Language Models are Few-Shot Learners","priority":3},{"title":"Scaling Laws for Autoregressive Generative Modeling","priority":0},{"title":"Zero-Shot Text-to-Image Generation","priority":2},{"title":"Hierarchical Text-Conditional Image Generation with CLIP Latents","priority":2},{"title":"Generative Pretraining from Pixels","priority":0}],"keywords":["NLP","Language Models","Codex (OpenAI)","GPT","GPT-3","Issues","Scaling Laws","Machine Learning","Generative Models","Dall-E","Dall-E 2","Systems, Libraries, Services, Tools","Deep Learning","Image GPT"]}