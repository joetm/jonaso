{"docs":[{"title":"Evaluating ChatGPT\u2019s Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness","priority":3},{"title":"Gotta Catch \u2019Em All: Using Honeypots to Catch Adversarial Attacks on Neural Networks","priority":1},{"title":"Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study","priority":0},{"title":"ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs","priority":2},{"title":"Shake to Leak: Fine-tuning Diffusion Models Can Amplify the Generative Privacy Risk","priority":0}],"keywords":["Knowledge","Information Extraction","ChatGPT","NLP","Issues","Adversarial Attacks","Adversarial Example Defense","Honeypots","Trapdoors","Augmented Language Models","Retrieval Pretraining","Jailbreaks","ASCII Smuggling","ASCII Art Prompt","Machine Learning","Generative Deep Learning","Diffusion","Privacy","Shake-to-Leak (S2L)"]}