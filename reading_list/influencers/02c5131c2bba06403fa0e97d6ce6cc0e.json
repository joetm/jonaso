{"docs":[{"title":"What Makes Good In-Context Examples for GPT-3?","priority":1},{"title":"LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS","priority":2},{"title":"Learning From Mistakes Makes LLM Better Reasoner","priority":2},{"title":"Meet in the Middle: A New Pre-training Paradigm","priority":1},{"title":"SUPERVISED KNOWLEDGE MAKES LARGE LANGUAGE MODELS BETTER IN-CONTEXT LEARNERS","priority":2}],"keywords":["Prompt Engineering","Prompt Techniques","Retrieval-Augmented Prompting","NLP","Fine-Tuning","Low-Rank Adaptation, LoRA","Reasoning","LeMa, Learning from Mistakes","Machine Learning","Training","Meet in the Middle","In-Context Learning","SuperContext"]}