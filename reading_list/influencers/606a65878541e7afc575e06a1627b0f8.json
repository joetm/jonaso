{"docs":[{"title":"Anchors: High-Precision Model-Agnostic Explanations","priority":1},{"title":"Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models","priority":0},{"title":"ART: Automatic multi-step reasoning and tool-use for large language models","priority":2},{"title":"AUTOPROMPT: Eliciting Knowledge from Language Models with Automatically Generated Prompts","priority":1},{"title":"Calibrate Before Use: Improving Few-Shot Performance of Language Models","priority":2},{"title":"Impact of Pretraining Term Frequencies on Few-Shot Numerical Reasoning","priority":2},{"title":"WHAT\u2019S IN MY BIG DATA?","priority":3},{"title":"Universal Adversarial Triggers for Attacking and Analyzing NLP","priority":3}],"keywords":["AI","Explainable AI, XAI","Interpretability","Interpretability Tools","Anchors","Prompt Engineering","Prompt Techniques","Automatic Reasoning and Tool-Use (ART)","NLP","Fine-Tuning","Few-Shot Finetuning","AutoPrompt","Issues","Calibration","Contextual Calibration","Long-tail Knowledge","Training","Training Data","What's in My Big Data (WIMBD)","Machine Learning","Adversarial Machine Learning","Universal Adversarial Triggers"]}