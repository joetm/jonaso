{"docs":[{"title":"Word embeddings quantify 100 years of gender and ethnic stereotypes","priority":2},{"title":"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings","priority":3},{"title":"GPT detectors are biased against non-native English writers","priority":2},{"title":"ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations","priority":3},{"title":"TWIGMA: A dataset of AI-Generated Images with Metadata From Twitter","priority":3},{"title":"How Is ChatGPT\u2019s Behavior Changing over Time?","priority":1}],"keywords":["NLP","Issues","Bias, Discrimination","Word Embeddings Bias","Framework for Temporal Analysis of Word Embedding","Machine Learning","Natural Language Generation, NLG","Detecting Automatically Generated Text","Prompt Engineering","Databases","ArtWhisperer","TWIGMA","Language Models","GPT","ChatGPT","Performance Degradation"]}