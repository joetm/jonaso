{"docs":[{"title":"A Theory on Adam Instability in Large-Scale Machine Learning","priority":0},{"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models","priority":3},{"title":"Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning","priority":1}],"keywords":["NLP","Issues","Training Instability","Adam Instability","Language Models","LLaMA (Meta)","Llama 2","Machine Learning","Generative Deep Learning","Multimodal Generation","CM3Leon"]}