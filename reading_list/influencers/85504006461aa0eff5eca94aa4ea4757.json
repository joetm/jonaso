{"docs":[{"title":"Calibrate Before Use: Improving Few-Shot Performance of Language Models","priority":2},{"title":"Universal Adversarial Triggers for Attacking and Analyzing NLP","priority":3}],"keywords":["NLP","Issues","Calibration","Contextual Calibration","Machine Learning","Adversarial Machine Learning","Universal Adversarial Triggers"]}