{"docs":[{"title":"SLIP: Self-supervision meets Language-Image Pre-training","priority":0},{"title":"Scalable Diffusion Models with Transformers","priority":1},{"title":"DEMYSTIFYING CLIP DATA","priority":3}],"keywords":["Machine Learning","Generative Deep Learning","Text-to-Image","SLIP","Diffusion","Contrastive Learning, Multimodal Models","CLIP","MetaCLIP,  Metadata-Curated Language-Image Pre-training"]}