{"docs":[{"title":"Language Models are Few-Shot Learners","priority":3},{"title":"Measuring the Algorithmic Efficiency of Neural Networks","priority":1},{"title":"Scaling Laws for Autoregressive Generative Modeling","priority":0}],"keywords":["NLP","Natural Language Generation","Language Models","OpenAI GPT","GPT-3","Training Efficiency","Issues","Scaling Laws"]}