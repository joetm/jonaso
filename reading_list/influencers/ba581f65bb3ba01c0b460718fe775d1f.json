{"docs":[{"title":"Predictability and Surprise in Large Generative Models","priority":2},{"title":"Language Models are Few-Shot Learners","priority":3},{"title":"Measuring the Algorithmic Efficiency of Neural Networks","priority":1},{"title":"Scaling Laws for Autoregressive Generative Modeling","priority":0},{"title":"Extracting Training Data from Large Language Models","priority":1},{"title":"Prompt engineering","priority":0},{"title":"The Capacity for Moral Self-Correction in Large Language Models","priority":3},{"title":"Discovering Language Model Behaviors with Model-Written Evaluations","priority":3}],"keywords":["AI","Issues","Predictability and Surprise","NLP","Language Models","GPT","GPT-3","Training Efficiency","Scaling Laws","Machine Learning","Private Training Data","Training Data Extraction Attack","Prompt Engineering","General, Theory","Prompt Techniques","Moral Self-Correction","Evaluation","Model-Written Evaluations","Inverse Scaling in RLHF"]}