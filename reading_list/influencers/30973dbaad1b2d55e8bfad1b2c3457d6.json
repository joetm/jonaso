{"docs":[{"title":"JAILBREAKER: Automated Jailbreak Across Multiple Large Language Model Chatbots","priority":2},{"title":"Backdooring Textual Inversion for Concept Censorship","priority":2},{"title":"MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots","priority":2},{"title":"Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study","priority":2},{"title":"Towards Effective Prompt Stealing Attack against Text-to-Image Diffusion Models","priority":3}],"keywords":["NLP","Issues","Adversarial Attacks","Jailbreaks","Automated Jailbreak","Machine Learning","Generative Deep Learning","Text-to-Image","Stable Diffusion","Fine-tuning Stable Diffusion","Textual Inversion","Censorship","Prompt Stealing","Prometheus"]}