{"docs":[{"title":"FLASHATTENTION: Fast and Memory-Efficient Exact Attention with IO-Awareness","priority":1}],"keywords":["NLP","Transformers","Attention","Flash Attention"]}