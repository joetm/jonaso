{"docs":[{"title":"ART: Automatic multi-step reasoning and tool-use for large language models","priority":2},{"title":"Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping","priority":3},{"title":"SELF-INSTRUCT: Aligning Language Model with Self Generated Instructions","priority":3},{"title":"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?","priority":2}],"keywords":["Prompt Engineering","Prompt Techniques","Automatic Reasoning and Tool-Use (ART)","NLP","Fine-Tuning","Issues","Random Seeds, Brittleness","Early Stopping","Instruction Tuning","Self-Instruct","In-Context Learning","Meaning"]}