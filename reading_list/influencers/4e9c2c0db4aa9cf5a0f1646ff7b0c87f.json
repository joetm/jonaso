{"docs":[{"title":"CAN FOUNDATION MODELS HELP US ACHIEVE PERFECT SECRECY?","priority":0},{"title":"Can Foundation Models Wrangle Your Data?","priority":1},{"title":"ASK ME ANYTHING: A SIMPLE STRATEGY FOR PROMPTING LANGUAGE MODELS","priority":3},{"title":"HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution","priority":2},{"title":"Training Complex Models with Multi-Task Weak Supervision","priority":0},{"title":"Holistic Evaluation of Language Models","priority":2},{"title":"Robustness Gym: Unifying the NLP Evaluation Landscape","priority":1},{"title":"Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models","priority":1},{"title":"FLASHATTENTION: Fast and Memory-Efficient Exact Attention with IO-Awareness","priority":1}],"keywords":["AI","Foundation Models","Applications","Privacy Preservation","Prompt Engineering","Data Cleaning, Data Integration","Prompt Techniques","Ask Me Anything","NLP","Genome Sequences, DNA","HyenaDNA","Tools, NLP APIs","Stanford Snorkel MeTaL","Evaluation","Holistic Evaluation of Language Models (HELM)","Robustness Gym","Machine Learning","Training","Skill-it!","Transformers","Attention","Flash Attention"]}