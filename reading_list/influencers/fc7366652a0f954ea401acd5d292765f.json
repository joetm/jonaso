{"docs":[{"title":"Scaling Synthetic Data Creation with 1,000,000,000 Personas","priority":3},{"title":"Dense X Retrieval: What Retrieval Granularity Should We Use?","priority":3},{"title":"On the Underthinking of o1-Like LLMs Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs","priority":2},{"title":"DON\u2019T THROW AWAY YOUR PRETRAINED MODEL","priority":2}],"keywords":["NLP","Applications","Simulation","Personas","Persona Hub","Augmented Language Models","Retrieval-Augmented Generation (RAG)","Issues","Retrieval","Retrieval Granularity","Language Models","GPT","o1","Underthinking","Machine Learning","Training","Model Collaboration"]}