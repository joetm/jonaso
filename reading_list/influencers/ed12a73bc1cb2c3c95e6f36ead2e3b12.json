{"docs":[{"title":"SUPERVISED KNOWLEDGE MAKES LARGE LANGUAGE MODELS BETTER IN-CONTEXT LEARNERS","priority":2},{"title":"Scito2M: A 2 Million, 30-Year Cross-disciplinary Dataset for Temporal Scientometric Analysis","priority":3}],"keywords":["NLP","In-Context Learning","SuperContext","Meta-Research","Datasets","Scito2M"]}