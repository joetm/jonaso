{"docs":[{"title":"SUPERVISED KNOWLEDGE MAKES LARGE LANGUAGE MODELS BETTER IN-CONTEXT LEARNERS","priority":2},{"title":"Scito2M: A 2 Million, 30-Year Cross-disciplinary Dataset for Temporal Scientometric Analysis","priority":3},{"title":"AGENTREVIEW: Exploring Peer Review Dynamics with LLM Agents","priority":1}],"keywords":["NLP","In-Context Learning","SuperContext","Meta-Research","Datasets","Scito2M","Applications","Simulation","Generative Agents Simulation","Peer Review Simulation"]}