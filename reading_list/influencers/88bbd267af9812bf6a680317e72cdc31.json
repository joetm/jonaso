{"docs":[{"title":"A General Language Assistant as a Laboratory for Alignment","priority":3},{"title":"Predictability and Surprise in Large Generative Models","priority":2},{"title":"The Capacity for Moral Self-Correction in Large Language Models","priority":3},{"title":"Discovering Language Model Behaviors with Model-Written Evaluations","priority":2},{"title":"Evaluating Large Language Models Trained on Code","priority":3}],"keywords":["AI","Issues","Human-AI Alignment","Alignment with Human Values","Helpful, Honest, Harmless (HHH)","Predictability and Surprise","Prompt Engineering","Prompt Techniques","Moral Self-Correction","NLP","Scaling","Inverse Scaling","Model-Written Evaluations","Language Models","Codex (OpenAI)"]}