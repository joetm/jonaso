{"docs":[{"title":"Training language models to follow instructions with human feedback","priority":3},{"title":"WebGPT: Browser-assisted question-answering with human feedback","priority":2},{"title":"Learning to summarize from human feedback","priority":2},{"title":"Generative Pretraining from Pixels","priority":0},{"title":"WEAK-TO-STRONG GENERALIZATION: ELICITING STRONG CAPABILITIES WITH WEAK SUPERVISION","priority":3}],"keywords":["AI","Issues","Human-AI Alignment","InstructGPT","NLP","Language Models","GPT","WebGPT","Machine Learning","Reinforcement Learning","Reinforcement Learning with Human Feedback (RLHF)","Systems, Libraries, Services, Tools","Deep Learning","Image GPT","Impact, Future","Superalignment","Weak-to-strong Generalization"]}