{"docs":[{"title":"Fast Inference from Transformers via Speculative Decoding","priority":2},{"title":"DIFFUSION MODELS ARE REAL-TIME GAME ENGINES","priority":3},{"title":"SELECTIVE ATTENTION IMPROVES TRANSFORMER","priority":1}],"keywords":["NLP","Transformers","Speculative Decoding","Machine Learning","Generative Deep Learning","Diffusion","Game Engine","GameNGen","Attention","Selective Attention"]}