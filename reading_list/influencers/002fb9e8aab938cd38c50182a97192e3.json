{"docs":[{"title":"Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark","priority":1},{"title":"Natural Selection Favors AIs over Humans","priority":1},{"title":"REPRESENTATION ENGINEERING: A TOP-DOWN APPROACH TO AI TRANSPARENCY","priority":3},{"title":"Humanity\u2019s Last Exam Organizing Team","priority":2},{"title":"Superintelligence Strategy: Expert Version","priority":1},{"title":"A Definition of AGI","priority":3}],"keywords":["AI","Issues","Harm","Harmful Agent Behavior","Machiavelli","Singularity","Natural Selection, Darwinian Forces","Explainable AI, XAI","AI Transparency","Representation Engineering","Benchmarks, gold standards, datasets","Multimodal","Humanity's Last Exam (HLE)","General, Theory","Superintelligence","Mutual Assured AI Malfunction (MAIM)","General Intelligence, AGI"]}