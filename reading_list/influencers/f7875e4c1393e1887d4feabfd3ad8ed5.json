{"docs":[{"title":"Training Compute-Optimal Large Language Models","priority":2},{"title":"Accelerating Large Language Model Decoding with Speculative Sampling","priority":0},{"title":"Improving language models by retrieving from trillions of tokens","priority":2}],"keywords":["NLP","Language Models","Chinchilla (DeepMind)","Machine Learning","Sampling","Speculative Sampling","Augmented Language Models","RETRO"]}