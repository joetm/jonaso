{"docs":[{"title":"OPT: Open Pre-trained Transformer Language Models","priority":3},{"title":"A Theory on Adam Instability in Large-Scale Machine Learning","priority":0},{"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models","priority":3},{"title":"Retrieval Augmentation Reduces Hallucination in Conversation","priority":1}],"keywords":["NLP","Language Models","OPT (Meta)","Issues","Training Instability","Adam Instability","LLaMA (Meta)","Llama 2","Natural Language Generation, NLG","Summarization","Evaluating Summarization","F1 Score","Knowledge F1 (KF1)"]}