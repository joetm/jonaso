{"docs":[{"title":"LIMA: Less Is More for Alignment","priority":2},{"title":"Self-Alignment with Instruction Backtranslation","priority":3},{"title":"Byte Latent Transformer: Patches Scale Better Than Tokens","priority":3}],"keywords":["AI","Issues","Human-AI Alignment","LIMA","Self-Alignment","Instruction Backtranslation","NLP","Transformers","Byte Latent Transformer"]}