{"docs":[{"title":"Language Is Not All You Need: Aligning Perception with Language Models","priority":3},{"title":"Retentive Network: A Successor to Transformer for Large Language Models","priority":3},{"title":"TORCHSCALE: Transformers at Scale","priority":1}],"keywords":["AI","Issues","Human-AI Alignment","Perception","Kosmos-1","NLP","Retentive Networks","Language Models","Foundation Architectures","TorchScale"]}