{"docs":[{"title":"Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks","priority":1},{"title":"Practical Black-Box Attacks against Machine Learning","priority":1},{"title":"AI models collapse when trained on recursively generated data","priority":3}],"keywords":["NLP","Issues","Adversarial Attacks","Adversarial Example Defense","Distillation","Machine Learning","Adversarial Machine Learning","Generative Deep Learning","Training on Synthetic Data","Curse of Recursion","Model Collapse"]}