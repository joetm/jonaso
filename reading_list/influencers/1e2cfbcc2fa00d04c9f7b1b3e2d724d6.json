{"docs":[{"title":"Evaluating Large Language Models Trained on Code","priority":3},{"title":"Language Models are Few-Shot Learners","priority":3},{"title":"Introducing OpenAI","priority":0},{"title":"Robust Speech Recognition via Large-Scale Weak Supervision","priority":1},{"title":"Consistency Models","priority":2},{"title":"Zero-Shot Text-to-Image Generation","priority":2},{"title":"Jukebox: A Generative Model for Music","priority":1},{"title":"Generative Pretraining from Pixels","priority":0},{"title":"Learning Transferable Visual Models From Natural Language Supervision","priority":2}],"keywords":["NLP","Language Models","Codex (OpenAI)","GPT","GPT-3","Machine Learning","Issues","OpenAI","Applications","Speech Recognition","Speech Recognition Models","Whisper","Generative Deep Learning","Text-to-Image","Consistency Models (OpenAI)","Dall-E","Audio","Text-to-Music","Jukebox","Systems, Libraries, Services, Tools","Deep Learning","Image GPT","Contrastive Learning, Multimodal Models","CLIP"]}