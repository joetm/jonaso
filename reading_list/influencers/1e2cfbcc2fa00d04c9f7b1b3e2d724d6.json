{"docs":[{"title":"Ilya Sutskever, OpenAI\u2019s chief scientist, on his hopes and fears for the future of AI","priority":0},{"title":"Evaluating Large Language Models Trained on Code","priority":3},{"title":"Language Models are Few-Shot Learners","priority":3},{"title":"Introducing OpenAI","priority":0},{"title":"Robust Speech Recognition via Large-Scale Weak Supervision","priority":1},{"title":"Language Models are Unsupervised Multitask Learners","priority":2},{"title":"Zero-Shot Text-to-Image Generation","priority":2},{"title":"Jukebox: A Generative Model for Music","priority":1},{"title":"Consistency Models","priority":2},{"title":"Generative Pretraining from Pixels","priority":0},{"title":"Learning Transferable Visual Models From Natural Language Supervision","priority":2},{"title":"Effective Altruism Funded the \u201cAI Existential Risk\u201d Ecosystem with Half a Billion Dollars","priority":0},{"title":"WEAK-TO-STRONG GENERALIZATION: ELICITING STRONG CAPABILITIES WITH WEAK SUPERVISION","priority":3},{"title":"OpenAI and Elon Musk","priority":0},{"title":"Let\u2019s Verify Step by Step","priority":1},{"title":"John Carmack\u2019s \u2018Different Path\u2019 to Artificial General Intelligence","priority":1}],"keywords":["AI","Impact, Future","Superalignment","NLP","Language Models","Codex (OpenAI)","GPT","GPT-3","Few-Shot Learning","Machine Learning","Issues","OpenAI","Applications","Speech Recognition","Speech Recognition Models","Whisper","Generative Deep Learning","Few-shot","GPT-2","Text-to-Image","Dall-E","Dall-E 1","Audio","Text-to-Music","Jukebox","Diffusion","Consistency Models (OpenAI)","Systems, Libraries, Services, Tools","Deep Learning","Image GPT","Contrastive Learning, Multimodal Models","CLIP","Altruism","Effective Altruism","AI Regulation","Weak-to-strong Generalization","Lawsuits","Elon Musk vs. OpenAI","Training","Process Supervision","General, Theory"]}