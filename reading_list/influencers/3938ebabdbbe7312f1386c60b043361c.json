{"docs":[{"title":"Collect, Measure, Repeat: Reliability Factors for Responsible AI Data Collection","priority":1},{"title":"A Checklist to Combat Cognitive Biases in Crowdsourcing","priority":3},{"title":"Crowdsourcing StoryLines: Harnessing the Crowd for Causal Relation Annotation","priority":0},{"title":"CrowdTruth: Machine-Human Computation Framework for Harnessing Disagreement in Gathering Annotated Data","priority":2},{"title":"Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation","priority":2},{"title":"Casual Users and Rational Choices within Differential Privacy","priority":0},{"title":"Alan\u2019s Speakeasy \u2013 An Ecosystem for the Evaluation of Conversational Agents","priority":1},{"title":"From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming Text-to-Image Models","priority":3}],"keywords":["AI","Responsible AI","Crowdsourcing, Human Computation","Issues","Bias","Bias Checklist","Hypertext, Hypermedia","Narrative, Story, Fabula","Storylines","Process, Workflow, Worker Selection","CrowdTruth","Machine Learning","Generative Deep Learning","Safety Filters","Adversarial Nibbler","Privacy","Differential Privacy","NLP","Agents, Autonomous Task Management","Evaluation","Alan\u2019s Speakeasy","Failure Modes","Adversarial Redteaming","Seed2Harvest"]}