{"docs":[{"title":"Gorilla: Large Language Model Connected with Massive APIs","priority":2},{"title":"The Wisdom of Hindsight Makes Language Models Better Instruction Followers","priority":1},{"title":"Catch me if you can! How to beat GPT-4 with a 13B model","priority":1},{"title":"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena","priority":2},{"title":"RAFT: Adapting Language Model to Domain Speci c RAG","priority":3},{"title":"MEMGPT: TOWARDS LLMS AS OPERATING SYSTEMS","priority":3},{"title":"Efficient Memory Management for Large Language Model Serving with PagedAttention","priority":2}],"keywords":["NLP","Augmented Language Models","Gorilla","Machine Learning","Reinforcement Learning","Reinforcement Learning with Human Feedback (RLHF)","Hindsight Instruction Relabeling (HIR)","Issues","Training Data","Contamination","LLM Decontaminator","Evaluation","Chatbot Arena","Retrieval-Augmented Generation (RAG)","RAG Optimization, RAG Fine-Tuning, RAG Techniques","Retrieval-Augmented Fine-Tuning (RAFT)","Operating Systems","MemGPT","Inference","vllm"]}