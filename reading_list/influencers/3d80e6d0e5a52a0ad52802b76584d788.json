{"docs":[{"title":"Jailbreaking Black Box Large Language Models in Twenty Queries","priority":2},{"title":"Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs","priority":3}],"keywords":["NLP","Issues","Adversarial Attacks","Jailbreaks","Prompt Automatic Iterative Refinement (PAIR)","Prompt Engineering","Prompt Sensitivity"]}