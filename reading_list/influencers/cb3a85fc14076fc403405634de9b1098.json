{"docs":[{"title":"\u201cEveryone wants to do the model work, not the data work\u201d: Data Cascades in High-Stakes AI","priority":2},{"title":"Crowdsourcing in the Cultural Heritage Domain: Opportunities and Challenges","priority":3},{"title":"Crowd Truth: Harnessing disagreement in crowdsourcing a relation extraction gold standard","priority":3},{"title":"Truth Is a Lie: Crowd Truth and the Seven Myths of Human Annotation","priority":3},{"title":"Empirical Methodology for Crowdsourcing Ground Truth","priority":1},{"title":"Nichesourcing: Harnessing the Power of Crowds of Experts","priority":2},{"title":"Accurator: Nichesourcing for Cultural Heritage","priority":3},{"title":"Personalized nichesourcing","priority":1},{"title":"Crowdsourcing Subjective Tasks:  The Case Study of Understanding Toxicity in Online Discussions","priority":0},{"title":"The Rijksmuseum Collection as Linked Data","priority":2},{"title":"Semantic Web and Human Computation: the Status of an Emerging Field","priority":3}],"keywords":["Machine Learning","Issues","Data Quality","Data Cascades","Crowdsourcing, Human Computation","Applications","Cultural Heritage","Process, Workflow, Worker Selection, Task Design","CrowdTruth","Nichesourcing","Accurator","Subjectivity, Subjective Tasks","Museum","Rijksmuseum","Ontology Engineering","Crowdsourcing","General"]}