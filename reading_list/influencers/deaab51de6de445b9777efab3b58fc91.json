{"docs":[{"title":"Predictability and Surprise in Large Generative Models","priority":2},{"title":"Evaluating Large Language Models Trained on Code","priority":3},{"title":"Language Models are Few-Shot Learners","priority":3},{"title":"Scaling Laws for Autoregressive Generative Modeling","priority":0},{"title":"Rebel AI group raises record cash after machine learning schism","priority":0}],"keywords":["AI","Issues","Predictability and Surprise","NLP","Language Models","Codex (OpenAI)","GPT","GPT-3","Scaling Laws","Hype","Anthropic"]}