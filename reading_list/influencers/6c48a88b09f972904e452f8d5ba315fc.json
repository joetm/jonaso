{"docs":[{"title":"Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers","priority":2},{"title":"Retentive Network: A Successor to Transformer for Large Language Models","priority":3}],"keywords":["NLP","In-Context Learning","Meta-Optimizer","Retentive Networks"]}