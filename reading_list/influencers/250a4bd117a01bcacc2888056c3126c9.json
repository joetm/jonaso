{"docs":[{"title":"CAN MACHINES LEARN MORALITY? THE Delphi EXPERIMENT","priority":2},{"title":"Closed AI Models Make Bad Baselines","priority":1},{"title":"Queer In AI: A Case Study in Community-Led Participatory AI","priority":0},{"title":"Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus","priority":3},{"title":"SAFETYANALYST: INTERPRETABLE, TRANSPARENT, AND STEERABLE LLM SAFETY MODERATION","priority":1},{"title":"BIG5-CHAT: SHAPING LLM PERSONALITIES THROUGH TRAINING ON HUMAN-GROUNDED DATA","priority":1},{"title":"Medical Hallucination in Foundation Models and Their Impact on Healthcare","priority":3},{"title":"Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)","priority":3}],"keywords":["NLP","Issues","Morality","Delphi","Machine Learning","Evaluation","Closed Models Baselines","AI","Queer AI","Benchmarks, gold standards, datasets","Colossal Clean Crawled Corpus (C4)","Safety","SafetyAnalyst","Personality, Values, Demographics","Big5-Chat","Hallucination, Factual Information","Medical Hallucinations","Applications","Simulation","Hivemind","Infinity-Chat"]}