{"docs":[{"title":"Emergent Abilities of Large Language Models","priority":2},{"title":"SWITCH TRANSFORMERS: SCALING TO TRILLION PARAMETER MODELS WITH SIMPLE AND EFFICIENT SPARSITY","priority":2},{"title":"Scaling Instruction-Finetuned Language Models","priority":1}],"keywords":["NLP","General, Theory","Emergent Abilities","Language Models","Google Switch-C","Flan-T5","Instruction Finetuning"]}